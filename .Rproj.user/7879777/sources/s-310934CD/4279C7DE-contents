---
title: "Família de Sinalização"
author: "Thiago Pires"
navlink: "<div id = 'container'><img src = 'fgv-logo.png'/></div>"
date: "`r format(Sys.time(), '%d de %B, %Y')`"
output: markdowntemplates::skeleton
css: styles.css
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, message = FALSE, warning = FALSE)
```

```{r}

require(magrittr)
require(dplyr)
require(readxl)
require(ggplot2)
require(plotly)
require(DT)
require(reshape2)
require(captioner)
require(glue)
require(purrr)
require(tibble)
require(rthop)

fig_nums <- captioner(prefix = "Figura")
table_nums <- captioner(prefix = "Tabela")

dados <- read_xlsx("Sinalização - Base de dados - v2.xlsx", sheet = "dados")

dados %<>% 
  mutate(relevo = factor(relevo, levels = c("Plano", "Ondulado", "Montanhoso")),
         classe = factor(classe, levels = c("I", "II", "III")),
         tachas = factor(tachas, levels = c("Sim", "Não")),
         regiao = factor(regiao, levels = c("Centro-Oeste", "Nordeste", "Norte", "Sudeste", "Sul")))

# p-valor function format

pvalue <- function(x) {
  
  ifelse(x < .001, "p-valor < 0.001", glue("p-valor = {sprintf('%3.3f', x)}"))
  
}

```

# Introdução

O objetivo deste trabalho é verificar a relação entre custo e outros fatores em obras de sinalização. Através deste resultado será possível parametrizar os custos e assim poder prever o gasto em obras.

# Material e método

As variáveis analisadas na família sinalização foram:

```{r}

bind_rows(
  tibble(variavel = "relevo", descri = "Características de relevo da região", respostas = "Plano, Ondulado ou Montanhoso"),
  tibble(variavel = "classe", descri = "Classe da rodovia", respostas = "0, I, II, II ou IV"),
  tibble(variavel = "vmd", descri = "Volume médio diário", respostas = "VMD"),
  tibble(variavel = "tachas", descri = "Presença de tachas refletivas ao longo da via", respostas = "Sim ou Não"),
  tibble(variavel = "nfaixas", descri = "Número de faixas", respostas = "Número"),
  tibble(variavel = "regiao", descri = "Região geográfica da via", respostas = "Centro-Oeste, Nordeste, Norte, Sudeste ou Sul"),
  tibble(variavel = "area", descri = "Área da via", respostas = "Metros quadrados")) %>% 
  datatable(colnames = c("Variável", "Descrição", "Respostas"), 
            options = list(dom = "t"),
            rownames = FALSE, caption = table_nums("famsi", "Variáveis explicativas"))

shiny::tags$br()

```

Os dados foram analisados através de:

- Regressão linear simples e múltipla `lm()`
- Árvore de regressão `rpart::rpart()`
- Redes neurais `tfestimators::dnn_regressor()`

Foi utilizado o programa estatístico R versão 3.5.1 e no *backend* do ajuste das redes neurais foi utilizando o TensorFlow.

No diagnóstico e verificação dos pressupostos da regressão linear foi utilizado o teste de Shapiro (normalidade), Durbin-Watson (independência dos resíduos) e Breusch-Pagan (homocedasticidade). Para avaliar as predições foi utilizado o MAPE (*mean absolute percentage error*). 

# Resultados

## Analisando a variável dependente preço reajustado

O preço reajustado da amostra #30 é um outlier pela análise do boxplot (`r fig_nums("precosibox", display = "cite")`).

<center>
```{r fig.cap=fig_nums("precosibox", "Boxplot do preço reajustado de sinalização")}

dados %>% 
  plot_ly() %>% 
  add_boxplot(y = ~preco, x = "", name = "boxplot") %>% 
  add_markers(y = ~preco, x = "", text = ~amostra, hoverinfo = "text", name = "outlier", 
              data = dados %>% filter(isOutlier(preco, 1.5))) %>% 
  layout(yaxis = list(title = "Preço")) %>% 
  config(displayModeBar = FALSE)

```
</center>

Na `r table_nums("precosisum", display = "cite")` são apresentadas as medidas resumos da variável preço. Observa-se uma certa assimetria na distribuição onde possivelmente a média está sendo influenciada pelo *outlier* observado. O teste de Shapiro rejeitou a hipótese de normalidade (`r shapiro.test(dados %>% pull(preco))$p.value %>% pvalue`).

```{r}

dados %>% 
  summarise(`Média` = mean(preco), 
            `Desvio padrão` = sd(preco), 
            Mediana = median(preco),
            Iiq = quantile(preco, c(.25, .75), names = FALSE) %>% diff()) %>% 
  melt() %>%
  datatable(colnames = c("Medidas", "Valores"), 
            options = list(dom = "t"),
            rownames = FALSE, caption = table_nums("precosisum", "Medidas resumo da variável preço")) %>% 
  formatRound(columns = "value", digits = 2)

shiny::tags$br()

```

## Análise das variáveis explicativas

A variável VMD apresenta 7 outliers incluindo a amostra de #30 que também era um outlier na variável preço. A variável área não apresentou outliers.

<center>
```{r fig.cap=fig_nums("vmdsibox", "Boxplot da variável VMD")}

dados %>% 
  plot_ly() %>% 
  add_boxplot(y = ~vmd, x = "", name = "boxplot") %>% 
  add_markers(y = ~vmd, x = "", text = ~amostra, hoverinfo = "text", name = "outlier", 
              data = dados %>% filter(isOutlier(vmd, 1.5))) %>% 
  layout(yaxis = list(title = "VMD")) %>% 
  config(displayModeBar = FALSE)

```
</center>

<center>
```{r fig.cap=fig_nums("areasibox", "Boxplot da variável VMD")}

dados %>% 
  plot_ly() %>% 
  add_boxplot(y = ~area, x = "", name = "boxplot") %>% 
  layout(yaxis = list(title = "Área")) %>% 
  config(displayModeBar = FALSE)

```
</center>

A frequências das variáveis analisadas poderão ser vistas na `r table_nums("tablesi", display = "cite")`. Há um percentual maior de relevo ondulado (52,38%), somente uma obra não havia presença de tachas e a região que apresenta maior quantidade de obras é o Sudeste (26,19%) seguido pelo Sul (23,81%).

```{r}

dados %>% 
  select_if(is.factor) %>% 
  names() %>% 
  map_dfr(~ freq2(var = ., data = dados)) %>% 
  datatable(rownames = FALSE, 
            colnames = c("Variável", "Categoria", "N", "%"),
            options = list(dom = "t", pageLength = 15),
            caption = table_nums("tablesi", "Distribuição percentual das variáveis explicativas"))

shiny::tags$br()

```

Na `r fig_nums("hmexpli", display = "cite")` vemos uma correlação forte entre o número de faixas e vmd (0,752), entre relevo e presença de faixas (0,819). A variável região não foi incluída por ser uma variável nominal com mais de duas categorias.

<center>
```{r fig.cap=fig_nums("hmexpli", "Análise da correlação entre as variáveis explicativas")}

cormat <- dados %>% 
  select(-c(amostra, preco, regiao, tachas)) %>% 
  as.data.frame() %>% 
  polycor::hetcor() %$% correlations

cormat[upper.tri(cormat, diag = TRUE)] <- NA

cormat %<>% .[-1, -ncol(.)]

cormat %>% round(3) %>% 
  plot_ly(x = row.names(.), 
          y = row.names(.), 
          type = "heatmap", z = .) %>% 
  layout(yaxis = list(autorange = "reversed")) %>% 
  config(displayModeBar = FALSE)

```
</center>

## Análise de regressão

Na análise de regressão foi retirada a amostra #30 pelo fato de ter sido avaliada como outlier na variável preço e VMD. A presença de tachas também não foi incluída na análise por ter apenas uma observação sem a presença de tachas.

```{r}

set.seed(568)
dados_train <- dados %>% filter(amostra != 30) %>% sample_frac(.8)

dados_test <- dados %>% filter(amostra != 30) %>% anti_join(dados_train, by = "amostra")

```


Na `r table_nums("modunisi", display = "cite")` observa-se as análises univariadas de cada variável. As variáveis relevo, classe, vmd e area foram as que apresentaram p-valor menor do que 0,30.

```{r}

dados_train %>% 
  select(-c(amostra, preco, tachas)) %>% 
  map( ~lm(preco ~ .x, data = dados_train)) %>% 
  map(summary) %>% 
  map("fstatistic") %>% 
  enframe() %>% 
  rowwise() %>% 
  mutate(`p-value` = 1 - pf(value[1], value[2], value[3])) %>% 
  select(-value) %>% 
  datatable(rownames = FALSE,
            colnames = c("Variável", "P-valor"), 
            options = list(dom = "t"),
            caption = table_nums("modunisi", "Análise univariada")) %>% 
  formatRound(columns = "p-value", digits = 3)

shiny::tags$br()

```

Na `r table_nums("modmulsi", display = "cite")` são apresentados os resultados do modelo múltiplo. As variáveis classe, vmd e area foram as variáveis significativas considerando um nível de 0,05.

```{r}

model <- 
  dados_train %>% 
  lm(preco ~ relevo + classe + vmd + area, data = .)

model %>% summary() %>% broom::tidy() %>% 
  datatable(rownames = FALSE,
            colnames = c("Termos", "Estimativa", "Erro-padrão", "Estatística", "P-valor"),
            options = list(dom = "t"),
            caption = table_nums("modmulsi", "Análise múltipla")) %>% 
  formatRound(columns = c("estimate", "std.error", "statistic", "p.value"), digits = c(2, 2, 2, 3))

shiny::tags$br()

```

Na `r table_nums("modmulsi2", display = "cite")` estão os resultados reajustados do modelo múltiplo mantendo as variáveis significativas do modelo anterior.

```{r}

model1 <- 
  dados_train %>% 
  lm(preco ~ classe + vmd + area, data = .)

model1 %>% summary() %>% broom::tidy() %>% 
  datatable(rownames = FALSE,
            colnames = c("Termos", "Estimativa", "Erro-padrão", "Estatística", "P-valor"),
            options = list(dom = "t"),
            caption = table_nums("modmulsi2", "Análise múltipla")) %>% 
  formatRound(columns = c("estimate", "std.error", "statistic", "p.value"), digits = c(2, 2, 2, 3))

shiny::tags$br()

```

O coeficiente de determinação deste modelo foi de `r model1 %>% summary() %$% adj.r.squared %>% round(3)` e o MAPE foi de `r predict(model1, dados_test %>% select(preco, classe, vmd, area)) %>% MLmetrics::MAPE(., dados_test %>% pull(preco)) %>% round(3)`.

### Diagnóstico

O teste de Shapiro não rejeita a hipótese de normalidade dos resíduos considerando um nível de significância de 0,05 (`r shapiro.test(model1$residuals)$p.value %>% pvalue`). Na `r table_nums("dwt", display = "cite")`, através do teste de Durbin-Watson (D-W), verifica-se que os resíduos não são autocorrelacionados.

```{r}

car::durbinWatsonTest(model1, 4) %>% broom::tidy() %>% 
  bind_cols(tibble(lag = 1:4)) %>% 
  select(6, 3, 1, 2) %>%
  datatable(rownames = FALSE,
            colnames = c("Lags", "Autocorrelação", "D-W", "P-valor"),
            options = list(dom = "t"),
            caption = table_nums("dwt", "Teste para verificação de autocorrelação do resíduos")) %>% 
  formatRound(columns = c("lag", "autocorrelation", "statistic", "p.value"), digits = c(0, 3, 3, 3))

shiny::tags$br()

```

Pelo teste de Breusch-Pagan não há evidências estatísticas para rejeitar a hipótese de homocedasticidade (`r lmtest::bptest(model1)$p.value %>% pvalue`).

## Análise de componentes principais não-linear

```{r results="hide"}

require(homals)

# análise

nlpca <- 
  dados_train %>% 
  select(-c(amostra, preco, tachas)) %>% 
  mutate_if(is.numeric, scale) %>% 
  as.data.frame() %>% 
  homals(data = ., ndim = 2, rank = 1, 
         level = c("nominal", "nominal", "numerical", "numerical", "nominal", "numerical"))

# cargas

cargas <- 
  nlpca$loadings %>% 
  enframe() %>% 
  rowwise() %>% 
  mutate(D1 = value[1], D2 = value[2]) %>% select(-value)

# autovalores

full_nlpca <- 
  dados_train %>% 
  mutate_if(is.numeric, scale) %>% 
  select(-c(amostra, preco, tachas)) %>% as.data.frame() %>% 
  homals(data = ., ndim = 6, rank = 1, 
         level = c("nominal", "nominal", "numerical", "numerical", "nominal", "numerical"))

autoval <- (full_nlpca$eigenvalues/sum(full_nlpca$eigenvalues) * 100) %>% sprintf("%2.1f", .)

```

Nos resultados da análise de componentes principais (`r fig_nums("nlpcaload", display = "cite")`) as duas componentes representam 53.9% de toda a variabilidade, observa-se que sobre a componente 1 há um peso da variável vmd; inversamente sobre esta mesma componente há um peso maior das variáveis classe, área e região. O número de faixas e o relevo apresentam um peso maior na segunda componente. Na `r fig_nums("nlpcacat", display = "cite")` podemos ver as relações entre as categorias das variáveis qualitativas e as quantitativas.

<center>
```{r fig.cap=fig_nums("nlpcaload", "Cargas fatorias do PCA não-linear")}

# cargas

cargas %>% plot_ly(x = ~D1, y = ~D2, text = ~name, hoverinfo = "text", opacity = 0,
                   width = 600, height = 500) %>% 
  config(displayModeBar = FALSE) %>% 
  add_annotations(x = ~D1,
                   y = ~D2,
                   xref = "x", yref = "y",
                   axref = "x", ayref = "y",
                   text = "",
                   showarrow = T,
                   ax = ~0,
                   ay = ~0) %>% 
  layout(xaxis = list(title = glue("Componente 1 ({autoval[1]})")),
         yaxis = list(title = glue("Componente 2 ({autoval[2]})")))

```
</center>

<center>
```{r fig.cap=fig_nums("nlpcacat", "Distribuição das respostas")}

# categorias

categorias <- 
  nlpca$catscores %>% 
  enframe()

getDatacat <- function(x) {
  categorias %>% 
    filter(name == x) %>% 
    pull(value) %>% 
    as.data.frame() %>% 
    rownames_to_column(var = "categor")}

plot_ly() %>% 
  config(displayModeBar = FALSE) %>% 
  add_markers(~D1, ~D2, data = getDatacat("relevo"), name = "relevo", text = ~categor, hoverinfo = "text") %>%
  add_markers(~D1, ~D2, data = getDatacat("classe"), name = "classe", text = ~categor, hoverinfo = "text") %>% 
  add_markers(~D1, ~D2, data = getDatacat("vmd"), name = "vmd", text = ~categor, hoverinfo = "text") %>%
  add_markers(~D1, ~D2, data = getDatacat("nfaixas"), name = "nfaixas", text = ~categor, hoverinfo = "text") %>%
  add_markers(~D1, ~D2, data = getDatacat("regiao"), name = "regiao", text = ~categor, hoverinfo = "text") %>%
  add_markers(~D1, ~D2, data = getDatacat("area"), name = "area", text = ~categor, hoverinfo = "text") %>% 
  layout(xaxis = list(title = glue("Componente 1")),
         yaxis = list(title = glue("Componente 2")))

```
</center>

## Árvore de regressão

Analisando os dados por meio da árvore de regressão foi selecionada somente a variável área como significativa. O custo médio de todas as obras aparece no topo do diagrama (aproximadamente R\$ 1,4 milhão). Uma área menor que 326 mil produziu um custo médio de R\$ 830 mil e uma área menor que 133 mil produziu um custo médio de R\$ 610 mil. Por outro lado uma área maior do que 236 mil produziu um custo médio de R\$ 2,3 milhões.

<center>
```{r fig.cap=fig_nums("regtree", "Diagrama com as estimativas da árvore de regressão")}

require(rpart)

regtree <- 
  dados_train %>% 
  rpart(preco ~ relevo + classe + vmd + tachas + nfaixas + regiao + area, data = .)

require(rpart.plot)

rpart.plot(regtree, roundint = FALSE)

```
</center>

### Diagnóstico

Na `r fig_nums("relative_error", display = "cite")` o erro relativo (1 - $R^2$) no corte é bem ruim (aproximadamente 0,453).

```{r results="hide"}

relerro <- printcp(regtree) %>% broom::tidy() %>% select(nsplit, rel.error)

```

<center>
```{r fig.cap=fig_nums("relative_error", "Erro relativo por número de cortes")}

relerro %>% 
  plot_ly(x = ~nsplit, y = ~rel.error, mode = "line") %>% 
  config(displayModeBar = FALSE) %>% 
  layout(xaxis = list(title = "Número de cortes"),
         yaxis = list(title = "Erro relativo"))

```
</center>

## Redes neurais

O modelo também foi analisado através de redes neurais com 80 e 60 neurônios na primeira e segunda camadas ocultas respectivamente. Na `r fig_nums("ddn", display = "cite")` está o diagrama com a estrura da rede.

<center>
```{r fig.cap=fig_nums("ddn", "Estrutura da rede neural estimada")}

DiagrammeR::grViz("DDN.gv")

```
</center>

```{r}

require(tfestimators)

# feature columns

cols <- feature_columns(
  column_numeric("vmd", "nfaixas", "area"),
  column_indicator(column_categorical_with_vocabulary_list("relevo", vocabulary_list = unique(dados_train$relevo))),
  column_indicator(column_categorical_with_vocabulary_list("classe", vocabulary_list = unique(dados_train$classe))),
  column_indicator(column_categorical_with_vocabulary_list("tachas", vocabulary_list = unique(dados_train$tachas))),
  column_indicator(column_categorical_with_vocabulary_list("regiao", vocabulary_list = unique(dados_train$regiao)))
  )

# input function

sinal_input_fn <- function(data, num_epochs = 1) {
  input_fn(data, 
           features = c("relevo", "classe", "vmd", "tachas", "nfaixas", "regiao", "area"), 
           response = "preco",
           batch_size = 20,
           num_epochs = num_epochs)
}

# estimator

dnn_model <- dnn_regressor(feature_columns = cols, hidden_units = c(80, 60))

# training

dados_train2 <- dados_train %>% 
  mutate_if(is.factor, as.character) %>% 
  as.data.frame()

dnn_model %>% 
  train(sinal_input_fn(dados_train2, num_epochs = 10))

# teste

dados_test2 <- dados_test %>% 
  mutate_if(is.factor, as.character) %>% 
  as.data.frame()

# dnn_model %>% evaluate(sinal_input_fn(dados_test2))

# prediction

dnn_predict <- dnn_model %>% predict(sinal_input_fn(dados_test2)) %>% unlist

```

O MAPE da análise foi de `r dnn_predict %>% MLmetrics::MAPE(., dados_test %>% pull(preco)) %>% round(3)`. 
